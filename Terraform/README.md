
To create any instances or s3 buckets or vpc any infrastructure we can create it through manually, but if we need many it is not possible to create manually each service or instance so we need a programmatical approach that is writing script in a language and running it to create the infrastructure in fraction of seconds that Is required 
For writing programmatically we need more scripting  knowledge so the cloud providers like aws has provided with CFT (cloud formation template) , it is just a template where we write in either in json/ yaml. CFT allows you to write the infrastructure as code like I need s3,vpc,ec2 In terms of templating language that is json/yaml
The infrastructure code can be shell scripting, python scripting  or templates like yaml, or json
 <img width="975" height="483" alt="image" src="https://github.com/user-attachments/assets/7584cfd7-7f3e-4ce9-821f-36e98a0d7a8f" />


Aws has cloud formation template and azure has same concept of writing an yaml/json  with azure resource manager in opem stack there are heat templates 	

Why terraform ?  universal approch
 Irrespective of the provider terraform can automate the infrastructure from one provider to others like aws,azure,gcp,openstack
Written in HCL hashicorp language 

It uses the approach API AS CODE 
The hcl code coverts to aws, azure or gcp terraform will apply the apis and create the infrastructure
Terraform has the largest market as of now
To get started with Terraform, it's important to understand some key terminology and concepts. Here are some fundamental terms and explanations.
1.	Provider: A provider is a plugin for Terraform that defines and manages resources for a specific cloud or infrastructure platform. Examples of providers include AWS, Azure, Google Cloud, and many others. You configure providers in your Terraform code to interact with the desired infrastructure platform.
2.	Resource: A resource is a specific infrastructure component that you want to create and manage using Terraform. Resources can include virtual machines, databases, storage buckets, network components, and more. Each resource has a type and configuration parameters that you define in your Terraform code.
3.	Module: A module is a reusable and encapsulated unit of Terraform code. Modules allow you to package infrastructure configurations, making it easier to maintain, share, and reuse them across different parts of your infrastructure. Modules can be your own creations or come from the Terraform Registry, which hosts community-contributed modules.
4.	Configuration File: Terraform uses configuration files (often with a .tf extension) to define the desired infrastructure state. These files specify providers, resources, variables, and other settings. The primary configuration file is usually named main.tf, but you can use multiple configuration files as well.
5.	Variable: Variables in Terraform are placeholders for values that can be passed into your configurations. They make your code more flexible and reusable by allowing you to define values outside of your code and pass them in when you apply the Terraform configuration.
6.	Output: Outputs are values generated by Terraform after the infrastructure has been created or updated. Outputs are typically used to display information or provide values to other parts of your infrastructure stack.
7.	State File: Terraform maintains a state file (often named terraform.tfstate) that keeps track of the current state of your infrastructure. This file is crucial for Terraform to understand what resources have been created and what changes need to be made during updates.
8.	Plan: A Terraform plan is a preview of changes that Terraform will make to your infrastructure. When you run terraform plan, Terraform analyzes your configuration and current state, then generates a plan detailing what actions it will take during the apply step
9.	Apply: The terraform apply command is used to execute the changes specified in the plan. It creates, updates, or destroys resources based on the Terraform configuration
10.	Workspace: Workspaces in Terraform are a way to manage multiple environments (e.g., development, staging, production) with separate configurations and state files. Workspaces help keep infrastructure configurations isolated and organized.
11.	Remote Backend: A remote backend is a storage location for your Terraform state files that is not stored locally. Popular choices for remote backends include Amazon S3, Azure Blob Storage, or HashiCorp Terraform Cloud. Remote backends enhance collaboration and provide better security and reliability for your state files.



Github codespaces
 <img width="604" height="312" alt="image" src="https://github.com/user-attachments/assets/10b5ce9d-917c-41c8-908d-08d99b6aa5af" />

 After the creating the code spaces there wont be terraform or aws so we need to install 
>add dev container configuration files
Modify active configuration
Search terraform-> select the tick marked one ->select keep defaults
>rebuild 
After the rebuild we can see the versions are available in codespaces
 <img width="975" height="186" alt="image" src="https://github.com/user-attachments/assets/bc21853f-85ed-48af-ba0a-12b203a60fc9" />

If we close and open the codespaces also still we will have the terraform and aws 	

How to configure aws to terraform

# Providers
A provider in Terraform is a plugin that enables interaction with an API. This includes cloud providers, SaaS providers, and other APIs. The providers are specified in the Terraform configuration code. They tell Terraform which services it needs to interact with.
For example, if you want to use Terraform to create a virtual machine on AWS, you would need to use the aws provider. The aws provider provides a set of resources that Terraform can use to create, manage, and destroy virtual machines on AWS.
Here is an example of how to use the aws provider in a Terraform configuration:
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0" # Change the AMI 
  instance_type = "t2.micro"
}
In this example, we are first defining the aws provider. We are specifying the region as us-east-1. Then, we are defining the aws_instance resource. We are specifying the AMI ID and the instance type.
When Terraform runs, it will first install the aws provider. Then, it will use the aws provider to create the virtual machine.
Here are some other examples of providers:
•	azurerm - for Azure
•	google - for Google Cloud Platform
•	kubernetes - for Kubernetes
•	openstack - for OpenStack
•	vsphere - for VMware vSphere
There are many other providers available, and new ones are being added all the time.
Providers are an essential part of Terraform. They allow Terraform to interact with a wide variety of cloud providers and other APIs. This makes Terraform a very versatile tool that can be used to manage a wide variety of infrastructure.
Different ways to configure providers in terraform
There are three main ways to configure providers in Terraform:
In the root module
This is the most common way to configure providers. The provider configuration block is placed in the root module of the Terraform configuration. This makes the provider configuration available to all the resources in the configuration.
provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
}
In a child module
You can also configure providers in a child module. This is useful if you want to reuse the same provider configuration in multiple resources.
module "aws_vpc" {
  source = "./aws_vpc"
  providers = {
    aws = aws.us-west-2
  }
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
  depends_on = [module.aws_vpc]
}
In the required_providers block
You can also configure providers in the required_providers block. This is useful if you want to make sure that a specific provider version is used.
terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "~> 3.79"
    }
  }
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
}
The best way to configure providers depends on your specific needs. If you are only using a single provider, then configuring it in the root module is the simplest option. If you are using multiple providers, or if you want to reuse the same provider configuration in multiple resources, then configuring it in a child module is a good option. And if you want to make sure that a specific provider version is used, then configuring it in the required_providers block is the best option.


What is providers?
Provider is a plugin that helps terraform where it has to create the entire project

Two popular are multi region architecture and multi cloud architecture

Multi cloud or multi  providers :
Multiple Providers

You can use multiple providers in one single terraform project. For example
1. Create a providers.tf file in the root directory of your Terraform project.
2. In the providers.tf file, define the AWS and Azure providers. For example:
```
provider "aws" {
  region = "us-east-1"
}

provider "azurerm" {
  subscription_id = "your-azure-subscription-id"
  client_id = "your-azure-client-id"
  client_secret = "your-azure-client-secret"
  tenant_id = "your-azure-tenant-id"
}
```

3. In your other Terraform configuration files, you can then use the aws and azurerm providers to create resources in AWS and Azure, respectively,

```
resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
}

resource "azurerm_virtual_machine" "example" {
  name = "example-vm"
  location = "eastus"
  size = "Standard_A1"
}
```

Multi region implementation :

You can make use of alias keyword to implement multi region infrastructure setup in terraform.
provider "aws" {
  alias = "us-east-1"
  region = "us-east-1"
}

provider "aws" {
  alias = "us-west-2"
  region = "us-west-2"
}

resource "aws_instance" "example" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
  provider = "aws.us-east-1"
}

resource "aws_instance" "example2" {
  ami = "ami-0123456789abcdef0"
  instance_type = "t2.micro"
  provider = "aws.us-west-2"
}



# Variables

Variables are used to parameterized to pass values 
We should not hardcode the values in terraform so we will use the variables to pass the values
We can reuse when we parameterized with particular values
There are two types of variables in terraform :
Input variable : if we want to pass some information to terraform 
Output variable :if we want to print terraform to print a particular value 

The output variables are used with output key word which means give back the details once the terraform apply command is successful

The structure to write the terraform file 
the provider configurations can be written in provider.tf file
The input variable that we pass will be in variables.tf
The output variables will be in output.tf
There will be main.tf

How to pass the values to the variables?
We will write a terraform.tfvars


# Conditional Expressions
Conditional expressions in Terraform are used to define conditional logic within your configurations. They allow you to make decisions or set values based on conditions. Conditional expressions are typically used to control whether resources are created or configured based on the evaluation of a condition
The syntax for a conditional expression in Terraform is:
condition ? true_val : false_val
•	condition is an expression that evaluates to either true or false.
•	true_val is the value that is returned if the condition is true.
•	false_val is the value that is returned if the condition is false.
Conditional Resource Creation Example
•	resource "aws_instance" "example" {
•	  count = var.create_instance ? 1 : 0
•	
•	  ami           = "ami-XXXXXXXXXXXXXXXXX"
•	  instance_type = "t2.micro"
•	}
In this example, the count attribute of the aws_instance resource uses a conditional expression. If the create_instance variable is true, it creates one EC2 instance. If create_instance is false, it creates zero instances, effectively skipping resource creation.

In resources block we are having more lines for example creating an s3 bucket for dev it should host in a public but in prod it should not host as public
For these kind of conditions in programming we use if else 
But in terraform we have conditional operators
```
The syntax is      condition ? true_val : false_val
variable "environment" {
  description = "Environment type"
  type        = string
  default     = "development"
}

variable "production_subnet_cidr" {
  description = "CIDR block for production subnet"
  type        = string
  default     = "10.0.1.0/24"
}

variable "development_subnet_cidr" {
  description = "CIDR block for development subnet"
  type        = string
  default     = "10.0.2.0/24"
}

resource "aws_security_group" "example" {
  name        = "example-sg"
  description = "Example security group"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = var.environment == "production" ? [var.production_subnet_cidr] : [var.development_subnet_cidr]
  }
}
```
We will use conditional operator when using multiple environments and in complicated archetieture.

Provider Configuration
The required_providers block in Terraform is used to declare and specify the required provider configurations for your Terraform module or configuration. It allows you to specify the provider name, source, and version constraints.
```
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 3.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = ">= 2.0, < 3.0"
    }
  }
}

```




# Built in functions:
Terraform is an infrastructure as code (IaC) tool that allows you to define and provision infrastructure resources in a declarative manner. Terraform provides a wide range of built-in functions that you can use within your configuration files (usually written in HashiCorp Configuration Language, or HCL) to manipulate and transform data. These functions help you perform various tasks when defining your infrastructure. Here are some commonly used built-in functions in Terraform:
```
1.	Concat (list1, list2, ...): Combines multiple lists into a single list.
variable "list1" {
  type    = list
  default = ["a", "b"]
}

variable "list2" {
  type    = list
  default = ["c", "d"]
}

output "combined_list" {
  value = concat(var.list1, var.list2)
}
2.	element(list, index): Returns the element at the specified index in a list.
variable "my_list" {
  type    = list
  default = ["apple", "banana", "cherry"]
}

output "selected_element" {
  value = element(var.my_list, 1) # Returns "banana"
}
3.	length(list): Returns the number of elements in a list.
variable "my_list" {
  type    = list
  default = ["apple", "banana", "cherry"]
}

output "list_length" {
  value = length(var.my_list) # Returns 3
}
4.	map(key, value): Creates a map from a list of keys and a list of values.
variable "keys" {
  type    = list
  default = ["name", "age"]
}

variable "values" {
  type    = list
  default = ["Alice", 30]
}

output "my_map" {
  value = map(var.keys, var.values) # Returns {"name" = "Alice", "age" = 30}
}
5.	lookup(map, key): Retrieves the value associated with a specific key in a map.
variable "my_map" {
  type    = map(string)
  default = {"name" = "Alice", "age" = "30"}
}

output "value" {
  value = lookup(var.my_map, "name") # Returns "Alice"
}
6.	join(separator, list): Joins the elements of a list into a single string using the specified separator.
variable "my_list" {
  type    = list
  default = ["apple", "banana", "cherry"]
}

output "joined_string" {
  value = join(", ", var.my_list) # Returns "apple, banana, cherry"
}
```
These are just a few examples of the built-in functions available in Terraform. You can find more functions and detailed documentation in the official Terraform documentation, which is regularly updated to include new features and improvements




# Modules:

Modules
The advantage of using Terraform modules in your infrastructure as code (IaC) projects lies in improved organization, reusability, and maintainability. Here are the key benefits:
1.	Modularity: Terraform modules allow you to break down your infrastructure configuration into smaller, self-contained components. This modularity makes it easier to manage and reason about your infrastructure because each module handles a specific piece of functionality, such as an EC2 instance, a database, or a network configuration.
2.	Reusability: With modules, you can create reusable templates for common infrastructure components. Instead of rewriting similar configurations for multiple projects, you can reuse modules across different Terraform projects. This reduces duplication and promotes consistency in your infrastructure.
3.	Simplified Collaboration: Modules make it easier for teams to collaborate on infrastructure projects. Different team members can work on separate modules independently, and then these modules can be combined to build complex infrastructure deployments. This division of labor can streamline development and reduce conflicts in the codebase.
4.	Versioning and Maintenance: Modules can have their own versioning, making it easier to manage updates and changes. When you update a module, you can increment its version, and other projects using that module can choose when to adopt the new version, helping to prevent unexpected changes in existing deployments.
5.	Abstraction: Modules can abstract away the complexity of underlying resources. For example, an EC2 instance module can hide the details of security groups, subnets, and other configurations, allowing users to focus on high-level parameters like instance type and image ID.
6.	Testing and Validation: Modules can be individually tested and validated, ensuring that they work correctly before being used in multiple projects. This reduces the risk of errors propagating across your infrastructure.
7.	Documentation: Modules promote self-documentation. When you define variables, outputs, and resource dependencies within a module, it becomes clear how the module should be used, making it easier for others (or your future self) to understand and work with.
8.	Scalability: As your infrastructure grows, modules provide a scalable approach to managing complexity. You can continue to create new modules for different components of your architecture, maintaining a clean and organized codebase.
9.	Security and Compliance: Modules can encapsulate security and compliance best practices. For instance, you can create a module for launching EC2 instances with predefined security groups, IAM roles, and other security-related configurations, ensuring consistency and compliance across your deployments.

Monolithic means writing the code in single base millions of lines code can be
In monolithic application if there is any bug we cant find it easily, lack of ownership, maintenance is difficult, testing is also difficult
Similarly in terraform also if we follow all the code in single base of writing everything in one place can cause issues like w cant easily find, lack of owner ship, maintenance is difficult, no reusability, 
 <img width="975" height="466" alt="image" src="https://github.com/user-attachments/assets/deae0a9c-2e2d-45fc-a723-cccb3cc698c0" />

Terraform.tfvars is used as a default for terraform passing values to the variables. Like we can pass the variables values to the main without declaring the file
If we are using other name than terraform,tfvars then we need pass terraform apply “name of tfvars”
 We need outputs to print whaterver the details we required,To get the outputs from the terraform we use outputs file  
If we need to what it created like ec2 what is the public ip for it what is the key security group all these details can get through outputs file


Similar to docker registry we are having terraform registry also at our own risk

Terraform statefile
state file is the heart of the terraform.
State file will record the or store the information of the infrastructure.
 Use of state file: after creating any resource we need to update the resource by adding other components the existing state file checks the statefile and finds what are the new changes and update those changes to the resource   eg: we created an ec2 instance with ami value and instance type now need to update the tag name so when we execute the terraform apply it will check the difference b/w the existing terraform statefile and updated the tag to the existing 
If no statefile then it will create a new ec2 instance 
Statefile is used for updating the infrastructure
Statefile is used for destroying the infrastructure

Drawback in terraform statefile
1.	If the git hub repo is compromised then state file is compromised
2.	Everyone checks out the code, updates the code along with that they have to update the state file.
These draw backs can be fixed through the remote backend.
If we created something like remote backend then no need to create the state file in local or github
If we are using s3 bucket as remote backend then it will host the satefile 
If the statefile is  hosted in s3 bucket we can overcome the draw backs
1—complete restrict the s3 bucket access as it is in aws we can configure with IAM roles and polices
2--- with checkouts, updates in the code when we give terraform apply automatically the changes are pushed to the s3 bucket statefile when configure with remote backend.
How the terraform apply executes automatically?
When we run the terraform init it understands it is using the remote backend and my staefile is in s3 bucket and it will get the information from there
 If we are using terraform cloud we can host the remote backend in terraform cloud itself

Interview:
We are a devops team of 4 to 5 people where we have a github repo that hosts terraform code. We are using terraform project to create eks or vpc 3 tier architecture, instead of storing the statefile in github repo we will be using the aws s3 as remote backend.
If we want to make any changes in the existing terraform we will clone the code and after making the changes when we do terraform apply the code changes are made locally and remote backend s3 in the aws is updated after that  we will raise a git hub pull request then someone will accept the request and the changes are moved 

To read the statefile there is a command called terraform show
Why outputs is required ?
Outputs are required because the developers do not have access to the state file
To create the remote backend we need to create the backend.tf and we need to provide the backend configuration

When ever we try to run the terraform commands it will take the lock or try to control the state file
Suppose there is team of developers two are executing the terraform apply same time it will be confused to execute which so it will be locked when one of the developer started executing it will be locked for him only then other cant acces until lock is completed.

Multiple people try to execute only one person execute at a time.
 We need to maintain the lock somewhere where bcz statefile is not there locally there is a resource in aws called dynamo db
We can implement the locking mechanism through dynamoDB 

# Provisioners
<img width="581" height="536" alt="image" src="https://github.com/user-attachments/assets/047a109c-703a-4ac1-8dbf-d38d95c1493e" />

 
Terraform project: need to deploy an python app and if any changes made in that app automatically should be updated by terraform by creating the VPC  public subnet internet gateway and route table where internet gateway would be the destination for that route tableEC2 to deploy the application and expose the application to the outside world

In terraform for  security groups INBOUND configuration is declared as INGRESS and outbound configuration is declared as EGRESS

Terraform is used for infrastructure creating and updating but how to deploy an application?
There is a concept called provisioners 
Provisioners are used to execute and implement during the creation and destruction 
Using provisioners we can deploy the applications on the EC2 instance 
To use provisioners we need to connect to the ec2 instance first

Use of provisioners: as terraform is a powerful tool still there are some challenges like not able to install python unless we use the provisioners 
If we are not using provisioners we need to use others like ansible or shell to connect and execute 
There are two provisioners
1.remote exec provisioners
2.local exec provisioners  
1.remote exec provisioners: At the time of creating Ec2 instance only we can connect to the particular instance and install anything required like installing python, java, or executing as many as shell commands that are required\.
2.Local exec provisioners: if we want to print anything on the console or all the outputs from the created to a particular file 
File provisioner: It is used to copy files , suppose we have created a RDS instance  or  EC2 instance we want to copy some files, yaml,Json what ever the files then it is used 



# Terraform Workspaces
Terraform Workspaces: how to setup terraform workspaces for different environments in the organization

they need different infrastructure for dev stage and prod bcz there will be different requirements for each environments  example 
Dev need t2.micro stage need t2.medium and prod need t2.large  with different specifications using the same statefile it will update each time and there will be a issues in the infrastructure to avoid this we are using workspaces
 <img width="975" height="440" alt="image" src="https://github.com/user-attachments/assets/e1f45530-287c-4db7-a8e3-aaa3c290800a" />

single state file causing the problem 
Workspaces will create state file for environment
There will be a folder like terraformstate.d inside that there will be dev,stage,and prod depending upon how many environments we create
So when we are in the dev workspace the dev satefile updated
So when we are in the Stage workspace the Stage satefile updated
So when we are in the prod workspace the prod satefile updated

So when we are using the workspaces infrastructure is creating for the environment and they are not conflicting with each other



Secrets management in Terraform: whether it is Terraform, Ansible, or CI/CD or Kubernetes you need to learn the secrets management
<img width="806" height="385" alt="image" src="https://github.com/user-attachments/assets/06be4b25-45b8-4402-bfb1-1301886c952e" />

Hashicorp vault Is one of the most used for secret management 
We can integrate HashiCorp Vault with Terraform, Ansible, Ci/CD, and Kubernetes.
Vault is not available in your Ubuntu As a default package so we are adding HashiCorp package manager to the Ubuntu.
Secret Engines are the secrets you create in the HashiCorp valut
 
The process will be remain same for all of them
Path we will mount where we store even at the instance or mount it will store the encrypted information the decrypted information is stored in vault

After giving the path we will enable the engine
If we want to access it through Terraform or Ansible. But they don't have access. If you want to grant access, you need to create an role inside Hashicop Vault.





Access as iam access: in Access, we have a lot of options the most widely used is the app roll. App role is similar to IAM role. Creation of the roles is not supported by the user interface, only by command line.
 <img width="596" height="466" alt="image" src="https://github.com/user-attachments/assets/3755b6ae-ab0b-4ab5-b6ba-e3421687c7de" />

Similarly for IAM, we will be having Access ID and Secret key ID. Here we will be having app role and app role id.
polices as IAM Policies
Provider AWS 
Provider vault.
To create the infrastructure, we will be using a keyword called "resource" To retrieve the information, we will use the keyword called “data”

scenario based interview questions:

1.	Terraform Migration:
Suppose we are working on a cloud formation template in AWS where the infrastructure is created. But we want to move it to completely to Terraform how we will be doing?
A: there is a command called “Terraform import”
Challenges that faced:

2.Drift Detection.
Terraform will not understand the updates or creation of resources made in the user interface. Until we run a terraform plan we don’t no it. this is called Drift. And the scenario is called Drift Detection.
How to identify drift detection with Terraform?
--There is a command called Terraform refresh. We will be using the Cron jobs and make it run every 1 hour, every time it's depends on our requirement. Terraform refresh command will let you know if there are any changes.
-- We will use audit logs using Lambda functions or event notifiers will be notifying if any change is made 

Creating EKS cluster using VPC with Terraform:
Here we'll be creating a worker nodes with auto Scaling and security groups for security of VPC  and EKS cluster.
Always try to use modules for reusability
always try to use the version if you are writing it the first time, try to use the latest version


Best way to use Terraform + Ansible:
Terraform is used for infrastructure management when coming to configuration management, it's not that reliable. In the same way, some companies start for Ansible. Ansible is very great for configuration management but not for provisioning infrastructure.
The organizations needs an orchestrator combining both Terraform and Ansible
Orchestrator 
1.	Order of execution-- where after creating the infrastructure, configuration need to be updated.
2.	Policy Management-- strict policy management by not allowing users out of scope Or Company Compliances.
3.	RBAC Implementation—
Such one of the orchestrators is Spacelift.
Different components of spacelift 
STACK: integrate your version control system in stack you can use variety of tools that spacelift supports and can define where these actions are updated example aws cloud

SPACES: Spaces are like the workspaces we can create all the components in dev,stage
Context: suppose we want to create some variables volumes or files across different stacks in your spacelift 
CLOUD INTEGRATION: within your spaces we can integrate the cloud services 
Policy: we can define or enforce policy based on user permissions like IAM Policy




